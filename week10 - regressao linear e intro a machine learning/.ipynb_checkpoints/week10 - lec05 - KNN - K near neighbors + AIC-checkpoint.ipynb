{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Near Neighbors (KNN)\n",
    "\n",
    "A técnica de KNN localiza os K primeiros vizinhos de um novo dado ponto. Coso os pontos próximos pertencem ao Grupo_i ele também pertencerá a este grupo. Pense que um rio separa duas regiões, e você abre um raio de 30 metros. Caso a margem direita ocupar mais este determinado círcuo, então o ponto onde você está pertense à margem direita.\n",
    "<br><br>\n",
    "Caso k for muito pequeno ocorre o overfiting, uma vez que acompanharemos sempre o vinho mais próximo, e como se acompanhássemos o ruído (linhas irregulares de uma fronteira). Se K aumentar, o novo ponto (vermelho) pegará a média da região, podendo mapear melhor a média da região. E se K for muito grande, estaremos sobre overfitting, e mapearemos muito mal o perfil da região ora em estudo.\n",
    "\n",
    "Para se saber o ótimo k existe um cálculo de \"Quantidade de Informação\" (AIC - Akaike Information criterion, ou BIC - bayesian information criterion) que mostrará o melhor K. Os conceitos de AKI e BIC.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Akaike_information_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PCA](../figure/knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo temos 5 registros da classe A e 5 registros da classe B, o objetivo é saber a qual classe o novo registro (bolinha vermelha) vai pertencer.\n",
    "\n",
    "Dado um novo registro ele vai calcular a distância desse registro com todas as amostras da base de dados de treinamento.\n",
    "\n",
    "Precisamos especificar um valor para o parâmetro K, ou seja, informar qual vai ser o número de vizinhos que serão comparados.\n",
    "\n",
    "No exemplo temos K=3, então ele vai pegar somente as três amostras mais próximas para fazer a comparação.\n",
    "\n",
    "Das 3 amostras de treinamento mais próximas do novo registro, 2 são da classe B e 1 da classe A, portanto como existem mais vizinhos da classe B, esse novo registro pertencerá a classe B.\n",
    "\n",
    "texto de: https://minerandodados.com.br/machine-learning-na-pratica-knn-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd # pandas e seu alias pd\n",
    "import numpy as np  # numpy  e seu alias np\n",
    "\n",
    "from   scipy import stats\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sys.path.insert(1, '../libs/')\n",
    "from stat_lib import *\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt # matplotlib e seu alias plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abrindo a tabela de Iris de Fisher & Anderson\n",
    "  - vamos pegar as 4 colunas de dados \n",
    "  - vamos pegar 70% dos dados para treinamento\n",
    "  - vamos pegar 30% dos dados para avaliação (testes)\n",
    "  - por fim vamos calcular o AIC, para diferentes valores de K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../data/Iris.csv\"\n",
    "if os.path.exists(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "else:\n",
    "    print(\"Impossível abrir '%s'\"%(fname))\n",
    "    raise('Error')\n",
    "    \n",
    "print(df.shape)\n",
    "df.columns = ['id', 'sepal_len', 'sepal_width', 'petal_len', 'petal_width', 'species']\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = df[ ['sepal_len', 'sepal_width', 'petal_len', 'petal_width']]\n",
    "\n",
    "colors = ['red', 'blue', 'green']\n",
    "specColors = ['red']*50 + ['blue']*50 + ['green']*50\n",
    "\n",
    "y = [0]*50 + [1]*50 + [2]*50\n",
    "species = df.species.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como temos 4 medidas (pétalas & sépalas x largura e comprimento)\n",
    "### Normalizamos estes valores pois se um for de grande magnitude e dispersão, fará um viés com relação aos outros\n",
    "### Normalizar (ou standardizar) significa subtrair a média e dividir pelo desvio padrão\n",
    "  - Esta operação é similar ao que se faz na distribuiçao Z\n",
    "  - Lembre-se que cada distribuição terá seu padrão, apesar das 4 se aproximarem da Normal\n",
    "  - Neste caso folhas largas e compridas ficaram num canto do hiper-espaço\n",
    "  - e folhas finas e curtas noutro canto do hiper-espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=6)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma tabela de confusão é uma tabela que se pode analisar o que se acertou ou errou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aic(n, mse, num_params):\n",
    "    aic = n * log(mse) + 2 * num_params\n",
    "    return aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.sum(cm)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = cm / N\n",
    "cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ll(cm):\n",
    "    cmp = cm / N\n",
    "\n",
    "    ll = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # print(i, j, cmp[i,j])\n",
    "            if cm[i,j] > 0 and cmp[i,j] > 0:\n",
    "                ll += cm[i,j] * np.log(cmp[i,j])\n",
    "    return ll        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_ll(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = []\n",
    "KS = np.arange(4, 25)\n",
    "\n",
    "ll_best = -99999\n",
    "kbest = -1\n",
    "cm_best = None\n",
    "\n",
    "for K in KS:\n",
    "    classifier = KNeighborsClassifier(n_neighbors=K)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ll = calc_ll(cm)\n",
    "    \n",
    "    if ll > ll_best:\n",
    "        ll_best = ll\n",
    "        kbest = K\n",
    "        cm_best = cm\n",
    "    \n",
    "    lls.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(KS, lls)\n",
    "\n",
    "plt.ylabel(\"log-likelihood (ll)\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.title(\"KNN - K best choice\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_best, kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
